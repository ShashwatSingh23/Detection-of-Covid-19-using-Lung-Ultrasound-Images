{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-10-14T01:59:37.036319Z","iopub.execute_input":"2022-10-14T01:59:37.036684Z","iopub.status.idle":"2022-10-14T01:59:50.659266Z","shell.execute_reply.started":"2022-10-14T01:59:37.036603Z","shell.execute_reply":"2022-10-14T01:59:50.657900Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.7/548.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.8.1)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (6.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.7->timm) (4.3.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.64.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.7.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.28.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.12.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.1.0)\nInstalling collected packages: timm\nSuccessfully installed timm-0.6.11\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport torch\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedGroupKFold\nimport timm\nfrom tqdm import tqdm\nimport albumentations as A\nfrom collections import defaultdict\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import roc_auc_score,f1_score,accuracy_score,precision_score,recall_score\nfrom torch.cuda import amp\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time\nimport gc\nimport copy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-14T02:49:48.067092Z","iopub.execute_input":"2022-10-14T02:49:48.067478Z","iopub.status.idle":"2022-10-14T02:49:48.074807Z","shell.execute_reply.started":"2022-10-14T02:49:48.067442Z","shell.execute_reply":"2022-10-14T02:49:48.073793Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed          = 42\n    debug         = False # set debug=False for Full Training\n    model         =  'swin_tiny_patch4_window7_224'\n    batch_size    = 32\n    img_size      = [224, 224]\n    epochs        = 5\n    lr            = 1e-4\n    scheduler     = 'CosineAnnealingLR'\n    min_lr        = 1e-4\n    T_max         = 449\n    T_0           = 25\n    warmup_epochs = 0\n    wd            = 1e-6\n    n_accumulate  = 1\n    n_fold        = 5\n    folds         = [0, 1, 2, 3]\n    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:48.260791Z","iopub.execute_input":"2022-10-14T02:49:48.261349Z","iopub.status.idle":"2022-10-14T02:49:48.267948Z","shell.execute_reply.started":"2022-10-14T02:49:48.261311Z","shell.execute_reply":"2022-10-14T02:49:48.267005Z"},"trusted":true},"execution_count":198,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/old-ultra-sound-covid-detection/covid_data.csv')\n\ndef correct_path(idx):\n    path = '../input/old-ultra-sound-covid-detection/data/'+idx[6::]\n    return path\n\ndf['path'] = df['path'].apply(correct_path)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:48.495817Z","iopub.execute_input":"2022-10-14T02:49:48.496232Z","iopub.status.idle":"2022-10-14T02:49:48.529387Z","shell.execute_reply.started":"2022-10-14T02:49:48.496204Z","shell.execute_reply":"2022-10-14T02:49:48.528543Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"df['fold'] = -1\nskf = StratifiedGroupKFold(n_splits=4,shuffle=True,random_state=42)\nfor fold,(train_idx,test_idx) in enumerate(skf.split(df['path'],df['label'],groups=df['video_id'])):\n    df.loc[test_idx,'fold'] = fold","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:48.585842Z","iopub.execute_input":"2022-10-14T02:49:48.586133Z","iopub.status.idle":"2022-10-14T02:49:48.665208Z","shell.execute_reply.started":"2022-10-14T02:49:48.586103Z","shell.execute_reply":"2022-10-14T02:49:48.664381Z"},"trusted":true},"execution_count":200,"outputs":[]},{"cell_type":"code","source":"#df = df.head(1024)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:48.775884Z","iopub.execute_input":"2022-10-14T02:49:48.776437Z","iopub.status.idle":"2022-10-14T02:49:48.781048Z","shell.execute_reply.started":"2022-10-14T02:49:48.776399Z","shell.execute_reply":"2022-10-14T02:49:48.780119Z"},"trusted":true},"execution_count":201,"outputs":[]},{"cell_type":"code","source":"df['video_id'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:48.975827Z","iopub.execute_input":"2022-10-14T02:49:48.976143Z","iopub.status.idle":"2022-10-14T02:49:48.984937Z","shell.execute_reply.started":"2022-10-14T02:49:48.976113Z","shell.execute_reply":"2022-10-14T02:49:48.984017Z"},"trusted":true},"execution_count":202,"outputs":[{"execution_count":202,"output_type":"execute_result","data":{"text/plain":"array(['Video_0', 'Video_1', 'Video_2', 'Video_3', 'Video_4', 'Video_5',\n       'Video_6', 'Video_7', 'Video_8', 'Video_9', 'Video_10', 'Video_11',\n       'Video_12', 'Video_13', 'Video_14', 'Video_15', 'Video_16',\n       'Video_17', 'Video_18', 'Video_19', 'Video_20', 'Video_21',\n       'Video_22', 'Video_23', 'Video_24', 'Video_25', 'Video_26',\n       'Video_27', 'Video_28', 'Video_29', 'Video_30', 'Video_31',\n       'Video_32', 'Video_33', 'Video_34', 'Video_35', 'Video_36',\n       'Video_37', 'Video_38', 'Video_39', 'Video_40', 'Video_41',\n       'Video_42', 'Video_43', 'Video_44', 'Video_45', 'Video_46',\n       'Video_47', 'Video_48', 'Video_49', 'Video_50', 'Video_51',\n       'Video_52', 'Video_53', 'Video_54', 'Video_55', 'Video_56',\n       'Video_57', 'Video_58', 'Video_59', 'Video_60', 'Video_61',\n       'Video_62', 'Video_63', 'Video_64', 'Video_65', 'Video_66',\n       'Video_67', 'Video_68', 'Video_69', 'Video_70', 'Video_71',\n       'Video_72', 'Video_73', 'Video_74', 'Video_75', 'Video_76',\n       'Video_77', 'Video_78', 'Video_79', 'Video_80', 'Video_81',\n       'Video_82', 'Video_83', 'Video_84', 'Video_85', 'Video_86',\n       'Video_87', 'Video_88', 'Video_89', 'Video_90', 'Video_91',\n       'Video_92', 'Video_93', 'Video_94', 'Video_95', 'Video_96',\n       'Video_97', 'Video_98', 'Video_99', 'Video_100', 'Video_101',\n       'Video_102', 'Video_103', 'Video_104', 'Video_105', 'Video_106',\n       'Video_107', 'Video_108', 'Video_109', 'Video_110', 'Video_111',\n       'Video_112', 'Video_113', 'Video_114', 'Video_115', 'Video_116',\n       'Video_117', 'Video_118', 'Video_119', 'Video_120', 'Video_121',\n       'Video_122', 'Video_123', 'Video_124', 'Video_125', 'Video_126',\n       'Video_127', 'Video_128', 'Video_129', 'Video_130', 'Video_131'],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CovidDataset(Dataset):    \n    def __init__(self,df,transforms=None,is_valid=False):\n        self.df = df\n        self.transforms = transforms\n        self.is_valid = is_valid\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        img = cv2.imread(self.df['path'].iloc[idx])\n        label = self.df['label'].iloc[idx]\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        #img = torch.tensor(img,dtype=torch.float32)\n        img = img.to(torch.float32)\n        label = torch.tensor(label)\n        \n        if self.is_valid:\n            return img,label,self.df['video_id'].iloc[idx]\n        return img,label","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:49.300919Z","iopub.execute_input":"2022-10-14T02:49:49.301457Z","iopub.status.idle":"2022-10-14T02:49:49.309216Z","shell.execute_reply.started":"2022-10-14T02:49:49.301428Z","shell.execute_reply":"2022-10-14T02:49:49.308109Z"},"trusted":true},"execution_count":203,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.Resize(*CFG.img_size,interpolation=cv2.INTER_NEAREST),\n            #A.RandomBrightnessContrast(),\n            #A.CLAHE(),\n            #A.GaussNoise(),\n            #A.CenterCrop(*CFG.img_size),\n            A.Normalize(),\n            A.HorizontalFlip(),\n            ToTensorV2(),\n        ],p=1.0)\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(*CFG.img_size,interpolation=cv2.INTER_NEAREST),\n            #A.CenterCrop(*CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ],p=1.0)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:49.470814Z","iopub.execute_input":"2022-10-14T02:49:49.471609Z","iopub.status.idle":"2022-10-14T02:49:49.478116Z","shell.execute_reply.started":"2022-10-14T02:49:49.471573Z","shell.execute_reply":"2022-10-14T02:49:49.476833Z"},"trusted":true},"execution_count":204,"outputs":[]},{"cell_type":"code","source":"class BaseModel(nn.Module):\n    def __init__(self,cfg,pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(cfg.model,pretrained=pretrained)\n        self.model.head = nn.Linear(self.model.head.in_features,3)\n        \n    def forward(self,x):\n        output = self.model(x)\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:49.635745Z","iopub.execute_input":"2022-10-14T02:49:49.636020Z","iopub.status.idle":"2022-10-14T02:49:49.641883Z","shell.execute_reply.started":"2022-10-14T02:49:49.635995Z","shell.execute_reply":"2022-10-14T02:49:49.640805Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    scaler = amp.GradScaler()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    epoch_loss = 0\n    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n    for step, (images, labels) in pbar:\n        labels = labels.type(torch.LongTensor)\n        images = images.to(device, dtype=torch.float)\n        labels  = labels.to(device)\n        \n        batch_size = images.size(0)\n        \n        with amp.autocast(enabled=True):\n            y_pred = model(images)\n            loss   = criterion(y_pred, labels)\n            loss   = loss / CFG.n_accumulate\n            \n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n    \n        if (step + 1) % CFG.n_accumulate == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        #print(epoch_loss)\n        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n        current_lr = optimizer.param_groups[0]['lr']\n        pbar.set_postfix(train_loss=f'{epoch_loss:0.4f}',\n                        lr=f'{current_lr:0.5f}',\n                        gpu_mem=f'{mem:0.2f} GB')\n        torch.cuda.empty_cache()\n        gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:49.760688Z","iopub.execute_input":"2022-10-14T02:49:49.761287Z","iopub.status.idle":"2022-10-14T02:49:49.771994Z","shell.execute_reply.started":"2022-10-14T02:49:49.761252Z","shell.execute_reply":"2022-10-14T02:49:49.771010Z"},"trusted":true},"execution_count":206,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, device, epoch,df,fold):\n    model.eval()\n    epoch_loss = 0.0\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    val_scores = []\n    video_ids_list = list(df[df['fold'] == fold]['video_id'].unique())\n    video_ids_score = {}\n    video_ids_count = {}\n    for i in video_ids_list:\n        video_ids_score[i] = 0\n        \n    for i in video_ids_list:\n        df_1 = df[df['fold'] == fold].copy()\n        video_ids_count[i] = len(df_1[df['video_id']==i])\n        \n    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n    oof = pd.DataFrame()\n    scores = np.array([])\n    real_labels = np.array([])\n    for step, (images, labels, video_ids) in pbar:\n        #images = images.type(torch.LongTensor)\n        labels = labels.type(torch.LongTensor)\n        images  = images.to(device, dtype=torch.float)\n        labels   = labels.to(device)\n        \n        \n        batch_size = images.size(0)\n        \n        y_pred  = model(images)\n        #print(y_pred)\n        #print(labels)\n        loss    = criterion(y_pred, labels)\n        \n        \n            \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        preds = y_pred.cpu().detach().numpy()\n        preds = np.argmax(preds,axis=1).reshape(-1)\n        #print(scores)\n        scores = np.concatenate([scores,preds])\n        real_labels = np.concatenate([real_labels,labels.cpu().numpy()])\n        \n        \n        #y_pred = nn.Softmax()(y_pred)\n        \n        for i in range(len(video_ids)):\n            #video_ids_count[video_ids[i]] +=1\n            video_ids_score[video_ids[i]] += y_pred[i].cpu().detach().numpy()\n            \n        #val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n        #val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n        #val_scores.append([val_dice, val_jaccard])\n        \n        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n        current_lr = optimizer.param_groups[0]['lr']\n        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n                        lr=f'{current_lr:0.5f}',\n                        gpu_memory=f'{mem:0.2f} GB')\n    '''\n    scores = []\n    labels = []\n    for ids in video_ids_score:\n        video_ids_score[ids] = video_ids_score[ids]/video_ids_count[ids]\n    \n    for ids in video_ids_score:\n        video_ids_score[ids] = np.argmax(video_ids_score[ids])\n    \n    for ids in video_ids_score:\n        labels.append(df[df['video_id']==ids]['label'].iloc[0])\n        scores.append(float(video_ids_score[ids]))\n    scores = np.array(scores)\n    '''\n    #val_auc = roc_auc_score(labels,list(scores))\n    \n    labels = real_labels\n    print(labels.shape)\n    print(scores.shape)\n    val_scores = f1_score(labels,scores, average='macro')\n    val_accuracy = accuracy_score(labels,scores)\n    precision = precision_score(labels,scores, average='macro')\n    recall = recall_score(labels,scores, average='macro')\n    video_ids_1 = []\n    for ids in video_ids_score:\n        video_ids_1.append(ids)\n    #oof['video_id'] = video_ids_1\n    #oof['preds'] = scores\n    #oof['labels'] = labels\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    return epoch_loss, val_scores, val_accuracy, precision, recall","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:50.128014Z","iopub.execute_input":"2022-10-14T02:49:50.128333Z","iopub.status.idle":"2022-10-14T02:49:50.143360Z","shell.execute_reply.started":"2022-10-14T02:49:50.128306Z","shell.execute_reply":"2022-10-14T02:49:50.142433Z"},"trusted":true},"execution_count":207,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs,df,fold):\n    \n    if torch.cuda.is_available():\n        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_score      = -np.inf\n    best_epoch     = -1\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        print(f'Epoch {epoch}/{num_epochs}', end='')\n        train_loss = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader,\n                                     device=CFG.device, epoch=epoch)\n        val_loss, val_scores, val_accuracy, precision, recall  = valid_one_epoch(model, valid_loader, \n                                                 device=CFG.device, \n                                                 epoch=epoch,df=df,fold=fold)\n    \n        history['Train Loss'].append(train_loss)\n        history['Valid Loss'].append(val_loss)\n        history['Valid Score'].append(val_scores)\n        \n        \n        #print(f'thresold: {best_th:0.4f}')\n        print(f'Valid F1 Score: {val_scores:0.4f}')\n        \n        print(f'Valid Accuracy Score: {val_accuracy:0.4f}')\n        #print(f'Valid AUC Score: {val_auc:0.4f}')\n        \n        print(f'Valid Precision Score: {precision:0.4f}')\n        print(f'Valid Recall Score: {recall:0.4f}')\n        \n        # deep copy the model\n        if val_scores >= best_score:\n            print(f\"Valid Score Improved ({best_score:0.4f} ---> {val_scores:0.4f})\")\n            #best_oof = oof\n            best_score    = val_scores\n            best_epoch   = epoch\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f\"best_epoch-{fold:02d}.bin\"\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved\")\n            \n        last_model_wts = copy.deepcopy(model.state_dict())\n        PATH = f\"last_epoch-{fold:02d}.bin\"\n        torch.save(model.state_dict(), PATH)\n            \n        print(); print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    #best_oof.to_csv(f'{fold}_oof.csv',index=False)\n    print(\"Best Score: {:.4f}\".format(best_score))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:50.272759Z","iopub.execute_input":"2022-10-14T02:49:50.273422Z","iopub.status.idle":"2022-10-14T02:49:50.285034Z","shell.execute_reply.started":"2022-10-14T02:49:50.273387Z","shell.execute_reply":"2022-10-14T02:49:50.284061Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CFG.scheduler == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max, \n                                                   eta_min=CFG.min_lr)\n    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0, \n                                                             eta_min=CFG.min_lr)\n    elif CFG.scheduler == 'ReduceLROnPlateau':\n        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                   mode='min',\n                                                   factor=0.1,\n                                                   patience=7,\n                                                   threshold=0.0001,\n                                                   min_lr=CFG.min_lr,)\n    elif CFG.scheduler == 'ExponentialLR':\n        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n    elif CFG.scheduler == 'None':\n        #scheduler = None\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:50.436136Z","iopub.execute_input":"2022-10-14T02:49:50.436461Z","iopub.status.idle":"2022-10-14T02:49:50.443044Z","shell.execute_reply.started":"2022-10-14T02:49:50.436437Z","shell.execute_reply":"2022-10-14T02:49:50.442100Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:50.615648Z","iopub.execute_input":"2022-10-14T02:49:50.616267Z","iopub.status.idle":"2022-10-14T02:49:50.621334Z","shell.execute_reply.started":"2022-10-14T02:49:50.616230Z","shell.execute_reply":"2022-10-14T02:49:50.620461Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"for fold in CFG.folds:\n    print(f'#'*15)\n    print(f'### Fold: {fold}')\n    print(f'#'*15)\n    train_df = df[df['fold'] !=fold].reset_index(drop=True)\n    valid_df = df[df['fold'] ==fold].reset_index(drop=True)\n    if CFG.debug:\n        train_df = train_df.head()\n        valid_df = valid_df.head()\n    \n    train_dataset = CovidDataset(train_df,transforms=get_transforms(data='train'),is_valid=False)\n    valid_dataset = CovidDataset(valid_df,transforms=get_transforms(data='valid'),is_valid=True)\n    \n    train_loader = DataLoader(train_dataset,batch_size=CFG.batch_size,shuffle=True,num_workers=2,drop_last=True)\n    valid_loader = DataLoader(valid_dataset,batch_size=CFG.batch_size,shuffle=False,num_workers=2,drop_last=False)\n    \n    cfg = CFG()\n    \n    model     = BaseModel(cfg,pretrained=True)\n    model.to(CFG.device)\n    optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n    scheduler = fetch_scheduler(optimizer)\n    model, history = run_training(model, optimizer, scheduler,\n                                  device=CFG.device,\n                                  num_epochs=CFG.epochs,\n                                 df=df,\n                                 fold=fold)","metadata":{"execution":{"iopub.status.busy":"2022-10-14T02:49:50.770999Z","iopub.execute_input":"2022-10-14T02:49:50.771284Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"###############\n### Fold: 0\n###############\ncuda: Tesla P100-PCIE-16GB\n\nEpoch 1/5","output_type":"stream"},{"name":"stderr","text":"Train :   0%|          | 0/449 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\nTrain : 100%|██████████| 449/449 [03:50<00:00,  1.95it/s, gpu_mem=4.03 GB, lr=0.00010, train_loss=0.2049]\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\nValid : 100%|██████████| 175/175 [00:30<00:00,  5.83it/s, gpu_memory=2.86 GB, lr=0.00010, valid_loss=0.6684]\n","output_type":"stream"},{"name":"stdout","text":"(5589,)\n(5589,)\nValid F1 Score: 0.8617\nValid Accuracy Score: 0.8980\nValid Precision Score: 0.9343\nValid Recall Score: 0.8256\nValid Score Improved (-inf ---> 0.8617)\nModel Saved\n\n\nEpoch 2/5","output_type":"stream"},{"name":"stderr","text":"Train : 100%|██████████| 449/449 [03:51<00:00,  1.94it/s, gpu_mem=4.14 GB, lr=0.00010, train_loss=0.2529]\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\nValid : 100%|██████████| 175/175 [00:30<00:00,  5.83it/s, gpu_memory=2.83 GB, lr=0.00010, valid_loss=0.7166]\n","output_type":"stream"},{"name":"stdout","text":"(5589,)\n(5589,)\nValid F1 Score: 0.7783\nValid Accuracy Score: 0.8250\nValid Precision Score: 0.7995\nValid Recall Score: 0.7932\n\n\nEpoch 3/5","output_type":"stream"},{"name":"stderr","text":"Train :  46%|████▌     | 206/449 [01:47<02:06,  1.92it/s, gpu_mem=4.15 GB, lr=0.00010, train_loss=0.1231]","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}